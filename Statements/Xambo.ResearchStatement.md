# Research statement

Anna Xambó, PhD 

[annaxambo.me](http://annaxambo.me)

## Vision & Mission

I envision developing my research towards contributing to advance **sound & music computing** research methods using an interdisciplinary approach, which can inform other STEM fields. My mission is to explore (1) new ways of interacting with sound and music, (2) new methods for understanding sound and music computing, and (3) new algorithms and systems to create sound and music. 
 
 
## Foci of research
 
In particular, my interest focuses on finding synergies between social sciences and engineering applied to music computing research, and connect my two backgrounds in engineering and artistic digital humanities. Social science research provides theoretical frameworks for understanding social structures and processes. Engineering research provides tools and methods to build computational systems. Sound and music computing research provides social, engineering and computational tools for understanding sound and music related phenomena. The discipline of HCI bridges the gap between social sciences and engineering by considering the human factors involved during the interactions with computers. My research is in alignment with HCI focusing on sound and music computing systems with social applications. The outcomes include algorithms and systems that support new practices in social sound and music computing, research methods for understanding these social interactions, and experiences that embrace these social interactions.
 
My research has **three foci**:

1. Development of real-time interactive systems and creative algorithms that explore new ways of interaction. 
2. Development of sound and music computing tools to raise awareness on sound-related issues e.g. environmental issues, and to raise awareness of socioeconomic problems that can be expressed via sound e.g. sound installations. 
3. Development of DIY tools and experiences for engaging non-musicians, especially girls, into music technology.

## Real-time interactive systems and creative algorithms

This research includes the development of tangible interfaces, web interfaces, gestural interfaces, and mobile interfaces applied to live coding, collaborative practices, improvisation practices, and spatial audio.
This branch is a follow-up of my own thesis work, the experience from my own practice as well as from EarSketch and its live coding capabilities. My previous research on understanding open forms in the wild by, for example, studying music improvisation with novel technologies, also informs this work. Also, see my PhD work on tabletops and ambisonics as a collaborative tool for sound design and performance with everyday sounds using spatial audio.

* Xambó, A., Freeman, J., Magerko, B., Shah, P. (2016). Challenges and new directions for collaborative live coding in the classroom. In *International Conference of Live Interfaces (ICLI 2016)*. Brighton, UK.
* Xambó, A., Hornecker, E., Marshall, P., Jordà, S., Dobbyn, C. and Laney, R. (2016). Exploring social interaction with a tangible music interface. *Interacting with Computers*.
* Xambó, A. (2015). *Tabletop Tangible Interfaces for Music Performance: Design and Evaluation*. Thesis. The Open University.
* Xambó, A., Hornecker, E., Marshall, P., Jordà, S., Dobbyn, C. and Laney, R. (2013). *Let's jam the Reactable: peer learning during musical improvisation with a tabletop tangible interface*. ACM Transactions on Computer-Human Interaction (TOCHI), 20(6), pp. 36:1–36:34.


## Raising awareness on sound-related and socioeconomic issues

This research is in alignment with the [environmental justice movement](http://serve-learn-sustain.gatech.edu/environmental-justice-series) in Georgia Tech related to sound-related issues e.g. noise pollution. I've started conversations with Jennifer Hirsch (Director of Center for Serve-Learn-Sustain, Georgia Institute of Technology) for the organization in Spring 2017 of an event around noise pollution within the mark of the environmental justice series.
Actions include participatory design and research e.g. working with low-income communities, and raising awareness of existing problems with computational tools, for example, visualization of world-wide data, or making urban interventions, such as the creation of situated sound installations. This branch also aligns with research in social computing developed at the School of Interactive Computing at Georgia Tech and research in visualization developed at the College of Computing. This perspective is inspired by [computational anthropology](https://www.technologyreview.com/s/528216/the-emerging-science-of-computational-anthropology/) and the use of data visualization to understand complex phenomena. This approach aligns with my previous research in data visualization as an aiding tool within the sound and music computing domain. 

* Xambó, A., Lerch, A., Freeman, J. (2016). Learning to code through MIR. In *Extended abstracts for the Late-Breaking Demo Session of the 17th International Society for Music Information Retrieval Conference (ISMIR 2016)*. New York. 
* Bogdanov, D., Haro, M., Fuhrmann, F., Xambó, A., Gómez, E. and Herrera, P. (2013). Semantic audio content-based music recommendation and visualization based on user preference examples. *Information Processing & Management*, 49(1), pp. 13-33.
* Haro, M.; Xambó, A.; Fuhrmann, F.; Bogdanov, D.; Gómez, E. and Herrera, P. (2010). The Musical Avatar: a visualization of musical preferences by means of audio content description. In *Proceedings of the 5th Audio Mostly Conference (AM '10)*. Piteå, Sweden.
* Roma, G. and Xambó, A. (2008). A tabletop waveform editor for live performance. In *Proceedings of the International Conference on New Interfaces for Musical Expression (NIME '08)*. Genoa, Italy.

## DIY tools and experiences for non-musicians, especially girls

This includes the development of STEAM educational tools that help students to engage with physics and maths through music technology using sensors, actuators, and microcontrollers. It also includes the development of tools that have a low-entry access to music making. It also includes the organization and dissemination of workshops in alignment with [Yorkshire sound women network](https://yorkshiresoundwomen.wordpress.com/) workshops for girls in the UK or Hackathons in alignment with the inclusive [Monthly Music Hackathon NYC](monthlymusichackathon.org). It also includes the collaboration with existing high school programs, such as the Magnet Program; as well as collaborations with museums and STEAM programs. This branch is a follow-up of my own thesis work at the Open University, as well as current work with the projects EarSketch and TuneTable at Georgia Tech. 

* Xambó, A., Drozda, B., Weisling, A., Magerko, B., Huet, M., Gasque, T., Freeman, J. (accepted) Experience and ownership with a tangible computational music installation for informal learning. In *Proceedings of the Tangible, Embedded, and Embodied Interaction Conference (TEI '17)*.
* Xambó, A., Lerch, A., Freeman, J. (2016). Learning to code through MIR. In *Extended abstracts for the Late-Breaking Demo Session of the 17th International Society for Music Information Retrieval Conference (ISMIR 2016)*. New York.
* Xambó, A. (2015). *Tabletop Tangible Interfaces for Music Performance: Design and Evaluation*. Thesis. The Open University.
* Freeman, J., Magerko, B., Edwards, D., Moore, R., McKlin, T., Xambó, A. (2015). *EarSketch: a STEAM approach to broadening participation in computer science principles*. In Proceedings of the IEEE Research in Equity and Sustained Participation in Engineering, Computing, and Technology (RESPECT '15). Charlotte, NC. pp. 109-110.
* Xambó, A., Roma, G., Laney, R., Dobbyn, C. and Jordà, S. (2014). SoundXY4: supporting tabletop collaboration and awareness with ambisonics spatialisation. In *Proceedings of the International Conference on New Interfaces for Musical Expression 2014 (NIME '14)*. London. pp. 249–252.
